import os
from pyspark.sql import SparkSession


KAFKA_TOPIC = os.getenv("KAFKA_TOPIC", "stock_prices")
KAFKA_SERVER = os.getenv("KAFKA_SERVER", "localhost:9092")
POSTGRES_URL = os.getenv("POSTGRES_URL", "jdbc:postgresql://localhost:5432/stocks")
POSTGRES_USER = os.getenv("POSTGRES_USER", "user")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD", "password")
POSTGRES_DRIVER_JAR = os.getenv("POSTGRES_DRIVER_JAR", "path/to/postgresql.jar")


spark = SparkSession.builder \
    .appName("StockPriceProcessor") \
    .config("spark.jars", POSTGRES_DRIVER_JAR) \
    .getOrCreate()


df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", KAFKA_SERVER) \
    .option("subscribe", KAFKA_TOPIC) \
    .load()


stock_df = df.selectExpr("CAST(value AS STRING)")

stock_df.writeStream \
    .outputMode("append") \
    .format("jdbc") \
    .option("url", POSTGRES_URL) \
    .option("dbtable", "stocks") \
    .option("user", POSTGRES_USER) \
    .option("password", POSTGRES_PASSWORD) \
    .start() \
    .awaitTermination()
